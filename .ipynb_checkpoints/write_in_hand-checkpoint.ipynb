{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ae5f42-a4e8-4522-b406-695b5fb90e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7408d169-315f-4073-96c2-058c07c9bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)  # 使用随机化种子使神经网络的初始化每次都相同\n",
    "class DigitDataset(Dataset):\n",
    "    def __init__(self,root):\n",
    "        self.root = root\n",
    "        self.files = os.listdir(root)\n",
    "        self.transform = transforms.ToTensor()   # 会把(H,W)转成(1,H,W)\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.files[idx]\n",
    "        label = int(fname[0])\n",
    "        path = os.path.join(self.root,fname)\n",
    "\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE) \n",
    "        img = self.transform(img)  # 转成tensor，自动 /255\n",
    "        return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c74112b-b482-4062-9c6b-ca173d89bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DigitDataset('./TrainingSet/')\n",
    "test_data = DigitDataset('./TestSet/')\n",
    "\n",
    "train_loader = Data.DataLoader(train_data, batch_size=50, shuffle=True)\n",
    "test_loader = Data.DataLoader(test_data, batch_size=200, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fce1de9-a12d-483d-958d-68414d0cbcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.out(x)\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c686ce0-074f-4df4-a076-0673cbd8df76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCH = 5\n",
    "LR = 0.001\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# for epoch in range(EPOCH):\n",
    "#     for step, (b_x, b_y) in enumerate(train_loader):\n",
    "#         output = cnn(b_x)\n",
    "#         loss = loss_func(output, b_y)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#         if step % 100 == 0:\n",
    "#             # 测试集计算 accuracy\n",
    "#             correct = 0\n",
    "#             total = 0\n",
    "#             for test_x, test_y in Data.DataLoader(test_data, batch_size=200, shuffle=False):\n",
    "#                 test_output = cnn(test_x)\n",
    "#                 pred = torch.max(test_output, 1)[1]\n",
    "#                 correct += (pred == test_y).sum().item()\n",
    "#                 total += test_y.size(0)\n",
    "\n",
    "#             acc = correct / total\n",
    "#             print(f'Epoch {epoch} | Step {step} | Loss {loss.item():.4f} | Test Acc {acc:.4f}')\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        output = cnn(b_x)\n",
    "        loss = loss_func(output, b_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "    # 每个 epoch 做一次测试\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for t_x, t_y in test_loader:\n",
    "        test_output = cnn(t_x)\n",
    "        pred = torch.max(test_output, 1)[1]\n",
    "        correct += (pred == t_y).sum().item()\n",
    "        total += t_y.size(0)\n",
    "    acc = correct / total\n",
    "    acc_list.append(acc)\n",
    "    print(f\"[Epoch {epoch}] Loss={loss.item():.4f}, Test Acc={acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b1424a-2ec0-4598-8bed-1b5d3f6ba099",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(loss_list)\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(acc_list)\n",
    "plt.title(\"Test Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for t_x, t_y in test_loader:\n",
    "    out = cnn(t_x)\n",
    "    pred = torch.max(out, 1)[1]\n",
    "    all_preds.extend(pred.numpy())\n",
    "    all_labels.extend(t_y.numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57619fa5-d9bc-4177-94af-462039120186",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_imgs = []\n",
    "wrong_pred = []\n",
    "wrong_true = []\n",
    "\n",
    "for img, label in test_data:\n",
    "    output = cnn(img.unsqueeze(0))\n",
    "    pred = torch.max(output,1)[1].item()\n",
    "    if pred != label:\n",
    "        wrong_imgs.append(img.squeeze().numpy())\n",
    "        wrong_pred.append(pred)\n",
    "        wrong_true.append(label)\n",
    "    if len(wrong_imgs) >= 16:\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(wrong_imgs[i], cmap='gray')\n",
    "    plt.title(f\"T:{wrong_true[i]} P:{wrong_pred[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(\"Failure Cases (Top 16)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481b58c-b41e-457a-85be-35a8f8a75574",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), 'digit_cnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fe03f2-2094-44d5-b6a6-fede3bed43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.load_state_dict(torch.load('digit_cnn.pkl'))\n",
    "cnn.eval()\n",
    "\n",
    "samples = []\n",
    "labels = []\n",
    "cnt = 0\n",
    "\n",
    "for img, label in test_data:\n",
    "    samples.append(img)\n",
    "    labels.append(label)\n",
    "    cnt += 1\n",
    "    if cnt >= 32:\n",
    "        break\n",
    "\n",
    "inputs = torch.stack(samples)\n",
    "test_output = cnn(inputs)\n",
    "pred_y = torch.max(test_output, 1)[1]\n",
    "\n",
    "print(\"Pred:\", pred_y.numpy())\n",
    "print(\"True:\", np.array(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf96082a-ebdb-4df7-8408-3a442573f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "grid = torchvision.utils.make_grid(inputs, nrow=8)\n",
    "img = grid.numpy().transpose(1, 2, 0)\n",
    "cv2.imshow(\"Samples\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9348733-453a-4877-9f2b-8f56b48ee12f",
   "metadata": {},
   "source": [
    "**TRY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a27c4d-bae3-4e0b-9e7e-f03630fa98dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)  # 使用随机化种子使神经网络的初始化每次都相同\n",
    "\n",
    "# # 超参数\n",
    "# EPOCH = 1  # 训练整批数据的次数\n",
    "# BATCH_SIZE = 50\n",
    "# LR = 0.001  # 学习率\n",
    "# DOWNLOAD_MNIST = False  # 表示还没有下载数据集，如果数据集下载好了就写False\n",
    "\n",
    "# # 下载mnist手写数据集\n",
    "# train_data = torchvision.datasets.MNIST(\n",
    "#     root='./TrainingSet/',  # 保存或提取的位置  会放在当前文件夹中\n",
    "#     train=True,  # true说明是用于训练的数据，false说明是用于测试的数据\n",
    "#     transform=torchvision.transforms.ToTensor(),  # 转换PIL.Image or numpy.ndarray\n",
    "\n",
    "#     download=DOWNLOAD_MNIST,  # 已经下载了就不需要下载了\n",
    "# )\n",
    "\n",
    "# test_data = torchvision.datasets.MNIST(\n",
    "#     root='./TestSet/',\n",
    "#     train=False  # 表明是测试集\n",
    "# )\n",
    "\n",
    "# # 批训练 50个samples， 1  channel，28x28 (50,1,28,28)\n",
    "# # Torch中的DataLoader是用来包装数据的工具，它能帮我们有效迭代数据，这样就可以进行批训练\n",
    "# train_loader = Data.DataLoader(\n",
    "#     dataset=train_data,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=True  # 是否打乱数据，一般都打乱\n",
    "# )\n",
    "\n",
    "# # 进行测试\n",
    "# # 为节约时间，测试时只测试前2000个\n",
    "# #\n",
    "# test_x = torch.unsqueeze(test_data.train_data, dim=1).type(torch.FloatTensor)[:2000] / 255\n",
    "# # torch.unsqueeze(a) 是用来对数据维度进行扩充，这样shape就从(2000,28,28)->(2000,1,28,28)\n",
    "# # 图像的pixel本来是0到255之间，除以255对图像进行归一化使取值范围在(0,1)\n",
    "# test_y = test_data.test_labels[:2000]\n",
    "\n",
    "\n",
    "# # 用class类来建立CNN模型\n",
    "# # CNN流程：卷积(Conv2d)-> 激励函数(ReLU)->池化(MaxPooling)->\n",
    "# #        卷积(Conv2d)-> 激励函数(ReLU)->池化(MaxPooling)->\n",
    "# #        展平多维的卷积成的特征图->接入全连接层(Linear)->输出\n",
    "\n",
    "# class CNN(nn.Module):  # 我们建立的CNN继承nn.Module这个模块\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         # 建立第一个卷积(Conv2d)-> 激励函数(ReLU)->池化(MaxPooling)\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             # 第一个卷积con2d\n",
    "#             nn.Conv2d(  # 输入图像大小(1,28,28)\n",
    "#                 in_channels=1,  # 输入图片的高度，因为minist数据集是灰度图像只有一个通道\n",
    "#                 out_channels=16,  # n_filters 卷积核的高度\n",
    "#                 kernel_size=5,  # filter size 卷积核的大小 也就是长x宽=5x5\n",
    "#                 stride=1,  # 步长\n",
    "#                 padding=2,  # 想要con2d输出的图片长宽不变，就进行补零操作 padding = (kernel_size-1)/2\n",
    "#             ),  # 输出图像大小(16,28,28)\n",
    "#             # 激活函数\n",
    "#             nn.ReLU(),\n",
    "#             # 池化，下采样\n",
    "#             nn.MaxPool2d(kernel_size=2),  # 在2x2空间下采样\n",
    "#             # 输出图像大小(16,14,14)\n",
    "#         )\n",
    "#         # 建立第二个卷积(Conv2d)-> 激励函数(ReLU)->池化(MaxPooling)\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             # 输入图像大小(16,14,14)\n",
    "#             nn.Conv2d(  # 也可以直接简化写成nn.Conv2d(16,32,5,1,2)\n",
    "#                 in_channels=16,\n",
    "#                 out_channels=32,\n",
    "#                 kernel_size=5,\n",
    "#                 stride=1,\n",
    "#                 padding=2\n",
    "#             ),\n",
    "#             # 输出图像大小 (32,14,14)\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#             # 输出图像大小(32,7,7)\n",
    "#         )\n",
    "#         # 建立全卷积连接层\n",
    "#         self.out = nn.Linear(32 * 7 * 7, 10)  # 输出是10个类\n",
    "\n",
    "#     # 下面定义x的传播路线\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)  # x先通过conv1\n",
    "#         x = self.conv2(x)  # 再通过conv2\n",
    "#         # 把每一个批次的每一个输入都拉成一个维度，即(batch_size,32*7*7)\n",
    "#         # 因为pytorch里特征的形式是[bs,channel,h,w]，所以x.size(0)就是batchsize\n",
    "#         x = x.view(x.size(0), -1)  # view就是把x弄成batchsize行个tensor\n",
    "#         output = self.out(x)\n",
    "#         return output\n",
    "\n",
    "\n",
    "# cnn = CNN()\n",
    "# print(cnn)\n",
    "\n",
    "# # 训练\n",
    "# # 把x和y 都放入Variable中，然后放入cnn中计算output，最后再计算误差\n",
    "\n",
    "# # 优化器选择Adam\n",
    "# optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "# # 损失函数\n",
    "# loss_func = nn.CrossEntropyLoss()  # 目标标签是one-hotted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf4047-0e03-4ba4-9a6c-a42d5021c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 开始训练\n",
    "# for epoch in range(EPOCH):\n",
    "#     for step, (b_x, b_y) in enumerate(train_loader):  # 分配batch data\n",
    "#         output = cnn(b_x)  # 先将数据放到cnn中计算output\n",
    "#         loss = loss_func(output, b_y)  # 输出和真实标签的loss，二者位置不可颠倒\n",
    "#         optimizer.zero_grad()  # 清除之前学到的梯度的参数\n",
    "#         loss.backward()  # 反向传播，计算梯度\n",
    "#         optimizer.step()  # 应用梯度\n",
    "\n",
    "#         if step % 50 == 0:\n",
    "#             test_output = cnn(test_x)\n",
    "#             pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "#             accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n",
    "#             print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)\n",
    "\n",
    "# torch.save(cnn.state_dict(), 'cnn2.pkl')#保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bd2aff-12a1-43e1-b428-ad9c4acd4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加载模型，调用时需将前面训练及保存模型的代码注释掉，否则会再训练一遍\n",
    "# cnn.load_state_dict(torch.load('cnn2.pkl'))\n",
    "# cnn.eval()\n",
    "# # print 10 predictions from test data\n",
    "# inputs = test_x[:32]  # 测试32个数据\n",
    "# test_output = cnn(inputs)\n",
    "# pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "# print(pred_y, 'prediction number')  # 打印识别后的数字\n",
    "# # print(test_y[:10].numpy(), 'real number')\n",
    "\n",
    "# img = torchvision.utils.make_grid(inputs)\n",
    "# img = img.numpy().transpose(1, 2, 0)\n",
    "\n",
    "# # 下面三行为改变图片的亮度\n",
    "# # std = [0.5, 0.5, 0.5]\n",
    "# # mean = [0.5, 0.5, 0.5]\n",
    "# # img = img * std + mean\n",
    "# cv2.imshow('win', img)  # opencv显示需要识别的数据图片\n",
    "# key_pressed = cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
